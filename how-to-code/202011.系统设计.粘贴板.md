# 网站粘贴板应用(Easy)

我们都用过计算机的`Copy`和`Paste`功能，其实本质上是计算机本地有一个粘贴板程序，每次我们`Ctrl + C`的时候，数据会被存储到剪贴板，而`Ctrl + V`会从剪贴板拿出文本数据，放到光标处。

现在我们要设计一个运行在`web`上的剪贴板应用。实现互联网上贡献的`复制粘贴`功能。

现有的一些服务网站: `pastebin.com`, `pastebin.ubuntu.com`等

实现功能：

1. 支持文本数据和图片数据
2. 每个粘贴生成一个唯一`URL` / 用户可以设置个性化`URL`
3. 可以设置`URL`存活时长，不设置的话也要定时清除

基本功能看起来挺简单的，在此基础上可以设计支持上传、拖拽等功能，但本文不考虑这些内容。

系统要求

1. 高可靠。除非过期，数据不会丢失
2. 高可用。服务一直可以用
3. 低延迟。快速访问URL内容
4. 安全性。URL带有私密性，不能被破解；数据量限制，不能滥用
5. 监控。PV / UV检测
6. RESTFul接口。

## 约束条件评估

### 读写比率 read / write

首先，从应用的角度来看，一个`URL`创立后，在生命周期内可以被访问多次。我们首先根据这个来预估一个`读/写`频率。

假设平均`5:1`的读写比率。

### 访问量 Traffic

其次，我们需要评估一下网络访问量。假设是一千万级别的访问量（一千万已经很大了，这种服务一般到一百万/天都很大了）。

```
				# 一天一千万的创建量，则平均下来要116次创建
				10M / (24h * 60m * 60s) ~= 116 pastes/s
				# 读写比率乘上，则每秒的URL访问量可以达到580次每秒的读取
				116 pastes/s * 5 = 580 reads/s
```

上面是平均数，也就是数学里面的算术平均，只能衡量大概的值。有经验的程序员还会评估一个峰值出来。

假设我们的峰值是平均值的`5`倍。那么压力位置的访问量能达到

```
				# 写入
				580 pastes/s
				# 访问
				2900 reads/s
```

根据上面计算的数值，我们可以估算出我们服务大概需要多少的`带宽`以及负载处理能力。


### 带宽 Brandwidth

功能里面我们有提到，需要限制数据的大小。假设我们的文本数据，平均大小为`20KB`。那么

```
				# 评估写入数据
				20KB * 116 = 2320 KB/s
				# 评估读取数据
				20KB * 580 = 11600 KB/s
```


### 存储 Storage

如果限制每个`write`请求的最大数据为`10MB`，平均值为上面我们提到的`10KB`，那么

```
				# 每天访问量
				10KB * 10M / (1024 * 1024) ~= 95GB
				# 每个数据默认保存1个月
				95GB * 30 = 2850 GB ~= 3T
```

存储耗费量巨大！

为了保证每个数据的独立性，需要考虑使用什么算法来计算`key`(或者说叫独立的URL)。我们熟知的`Base64`算法有`64^6(687亿 )`位独立数据。

因此再计算一下每个月的值

```
				# 每天一千万的写入量，一个月就有三亿条写入数据，每条数据需要有一个索引
				3 * 6 = 18 亿字节(base64 6个bit位表示一个数据， 因此乘6) = 18亿 / (1024 * 1024 * 1024 * 8) ~= 2GB
```

索引都需要`2GB`来存！

但是这`2GB`的量级和`3T`比起来，还是少了很多，因此我们就以`3T`作为整个存储的平均占用率。

但是实际上我们运营网站不会说买个`3T`的硬盘就开干了，按照`2/8`原则，我们要买大一点的硬盘

```
				# 给系统留余地
				3 T / 0.8 = 3.75 T ~= 4T

```

### 内存 Memory

这里可以很好的利用`LRU`算法了。(之前的文章有讲到过)热点问题，我们肯定希望能够直接访问到，不需要去读硬盘。

另外，我们的`2GB`数据其实也可以用`Redis`搞个`key-value`存储，方便我们索引数据地址，或者说快速返回。

如果用`LRU`算法和`redis`结合，热点问题控制在`4GB`以内，可以非常快速地对用户的`read`操作作出响应。

评估一下内存占用量

```
				# 一天的访问量
				50 M  * 10KB / (1024  * 1024) ~= 477GB
				# LRU算法缓存 5%的数据
				477 * 5% ～= 24GB
				# 这5%请求需要的key值
				50M * 5% * 6 / (1024 * 1024 * 8) = 1.8GB
				# 因此如果要实现LRU算法 + redis快速返回数据，大概需要
				24GB + 1.8GB = 26GB的实时内存占用量

```

## 顶层设计 High Level Design

顶层设计是解决大体架构的问题。

应用层可以根据我们的服务器数量，设置负载均衡。应用层下面，还需要有数据库层。另外如果有元数据(`key-value`)，可以再分一层。

```
user =>| application | => database
			 |    			   | => meta / hot data
       |             |
   Load Balance     Locker

```

也就是说在应用层，我们重点关注请求的并发量，做`负载均衡`。在数据层，我们主要关注`安全和一致性`，需要`加锁`访问。

## API设计 System API

API设计需要知道大概有哪些参数，接口交互

### 添加addPaste

参数列表

- key 唯一键值，可以由Base64或者hash算法计算，或者由其他方式。算法容量应该大于2GB数据。
- data 用户数据。图片其实也可以转为文本数据
- userInfo 创建者的信息。这个可以根据网站性质来决定需要哪些
- expire_date 过期时间，需要一个默认过期时间
- userUrl 用户自定义URL，如果没有传递的话，就使用我们自己生成的URL

以上为主要参数。

返回值

返回值为创建好的URL

### 读取 readPaste

参数列表

- key 唯一键值，区别唯一客户
- url 数据路径。这里可以换成数据库的key，但实际上我们给用户的是URL，利用URL查找到数据key也可以。

返回值

返回值为读取内容

### 过期 expirePaste

参数列表

参数列表和readPaste保持一致，expire其实就是删除。

### 定时任务 task

- type 过期类型。如果是分钟，就需要每分钟扫描对应数据是否过期，过期则调用expire方法。分钟、小时、天、月同理。


## 数据库 Database

根据上面的计算内容，我们考虑有几个模块

- 静态数据。用户paste的数据，是有持久化需求的，这一部分数据需要占用最大部分的硬盘存储
- 元数据。记录每条paste数据的映射、键值、url、用户信息等，虽然数据的条数和paste一一对应，但每条的数据量大大减少。
- 热点数据。内存数据库在这里发挥作用。

根据上面的分类，再去定义数据库字段、表格拆分，文档数据库、内存数据库的使用。

## 补充设计

随着系统运行起来，数据量达到甚至超过了我们的预估值，补充设计可以考虑的点有

1. 可能我们会需要一个服务单独分配Key，那么随之而来的是多一个存储Key的数据库和服务(避免重复、加快访问)
2. 定时任务也可以是独立的，这样不会影响应用层的处理效率，理论上清除垃圾数据不应该影响现有任务
3. 除了`redis+LRU`对索引做缓存，那些paste数据也可以设计一层缓存
4. `Restful`接口设计



