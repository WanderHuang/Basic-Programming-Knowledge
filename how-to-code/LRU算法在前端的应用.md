# 前端页面LRU算法的应用

最近在业务开发上遇到了性能问题，按常理来讲，偏后台应用的前端很难出现性能问题的，因为都是一些`CURD`操作而已。但我们目前的业务场景有这么几个特点

1. 用户在页面上停留时间很长，有会话聊天功能。
2. 每个会话关联了大量的信息
3. 用的一些第三方库(微服务)，让所有子应用合并后，页面很庞大(臃肿)
4. 中台化发展，让前端需要聚合的接口更多，单页面请求量膨胀

其实上面这些也不应该成为性能的瓶颈。

1. `chrome`给每个tab可支配的内存是足够用的，`100MB`内存的使用量对浏览器来说已经很大了
2. 除了接口响应时间不可控之外，其他的流程，用js处理速度已经足够了，除非数据量达到千万级别
3. 应用集成的问题其实应该用公共依赖抽取的方法来减少页面数据重复和内存占用膨胀
4. 浏览器已经提供了`localStorage`和`sessionStorage`的方式来持久化数据

在实际场景中，我们已经处理的优化有

1. `React`内用`React.memo`和`useMemo`减少`render`次数。当然也用到了`useCallback`
2. 接口聚合 & 减少重复发送请求
3. 大数据量的解构赋值代码重构，减少了瞬时内存占用量暴增和`cpu`占用率暴增的情况
4. 公共组件提取，当然也是为了减少`render`

但有一个场景上面提到的优化方案都没法覆盖

> 用户会话切换时，数据的保存和恢复

简单来看，我们用一个`Map`结构可以存下所有的会话及关联数据。但这个会有一个问题

> 随着时间推移，存活会话量增多，`Map`内的数据会不断膨胀，而且这种膨胀是不可阻挡的。你并不知道什么时候去删掉过期数据

所以你可能会说了，那我在一个会话失效的时候去删除对应的数据就行了嘛。但这有个内存泄漏的潜在风险

> 当频繁操作的会话固定在一个范围(如`20`个)，但所有会话都因为下一秒可能点击而无法失效时。上面的方法就回退到了最初的状态，还是没有解决根本问题。

## 最快获取`热点`

上面我们提到了这种场景。

> 我有几百个存活的会话数据，但在我访问页面的过程中，先处理的会话，后面再次访问的概率就降低了很多，因此我想要一种算法，让我最频繁访问的那些数据，能够快速拿到，不用从后端获取。

答案就是`LRU算法`。

`LRU算法`使用了`双向链表`来构成队列，每次操作会激活当前处理对象到队列的头部(`O(1)`时间)，且队列会有一个长度限制，超出长度限制的“老年代”数据就会被剔出队列。

这样就保证了我频繁操作的那`m`个(总量为`n`个，`m <= n`)数据，我可以用`O(1)`的时间进行读写。而剔出队列的那些数据，由于我访问的可能性很低，到访问时我再去后端取数据，也是可以接受的。

## 解决场景

上述的热点快速恢复策略，就是我们的`场景`

```txt
没有缓存: 会话切换  => 即时拉取数据 => 页面刷新

Map缓存: 会话切换 => 保存当前会话数据 => 读取下一个会话数据 => 页面刷新 |  内存线性增长

LRU缓存：会话切换 => 保存当前会话数据 => 读取下一个会话数据 =读到=> 页面刷新         | 最大内存占用限制
                                                            =没有=> 请求 => 页面刷新

```

## 优点

1. 内存控制，不会无限膨胀
2. 可以得到热点数据
3. 可以快速恢复页面状态
4. 抽象层内可以方便做持久化，不用单独对某个`Map`做持久化(`LRU => localstorage or IndexDB`)

## 后记

